{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93677575-47d1-4447-a6ed-0441ac5f014d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from transformers import AdamW, AutoTokenizer\n",
    "from commonlit_nn_kit import train_and_evaluate, forward_pass_uno_text_batch, compute_mse_loss, compute_rmse_loss, compute_rmse_score, UnoStacker\n",
    "from commonlit_nn_kit import clear_cuda, get_scheduler, get_optimizer_parameters, create_uno_text_dataloader, Saver, RobertaMaskAddedAttentionHeadRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1145e485-daa4-462c-bf77-2b2c093710b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {'seed': 42}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2043a8b-f7ac-4f6e-8556-cbbdccf4be66",
   "metadata": {},
   "source": [
    "# Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50bcf46-2026-42e8-bb8a-cd677f7f3c19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Alice looked at the jury-box, and saw that, in her haste, she had put the Lizard in head downwards, and the poor little thing was waving its tail about in a melancholy way, being quite unable to move. She soon got it out again, and put it right; ‘not that it signifies much,' she said to herself; ‘I should think it would be quite as much use in the trial one way up as the other.'\\nAs soon as the jury had a little recovered from the shock of being upset, and their slates and pencils had been found and handed back to them, they set to work very diligently to write out a history of the accident, all except the Lizard, who seemed too much overcome to do anything but sit with its mouth open, gazing up into the roof of the court.\\n‘What do you know about this business?' the King said to Alice.\\n‘Nothing,' said Alice.\\n‘Nothing whatever?' persisted the King.\\n‘Nothing whatever,' said Alice.</td>\n",
       "      <td>-0.432678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>Artificial intelligence (AI) is intelligence exhibited by machines. In computer science, an ideal \"intelligent\" machine is a flexible rational agent that perceives its environment and takes actions that maximize its chance of success at some goal. Colloquially, the term \"artificial intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\". As machines become increasingly capable, facilities once thought to require intelligence are removed from the definition. For example, optical character recognition is no longer perceived as an exemplar of \"artificial intelligence\" having become a routine technology. Capabilities still classified as AI include advanced Chess and Go systems and self-driving cars.\\nAI research is divided into subfields that focus on specific problems or on specific approaches or on the use of a particular tool or towards satisfying particular applications.</td>\n",
       "      <td>-1.161746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      excerpt  \\\n",
       "2089                                                                                          Alice looked at the jury-box, and saw that, in her haste, she had put the Lizard in head downwards, and the poor little thing was waving its tail about in a melancholy way, being quite unable to move. She soon got it out again, and put it right; ‘not that it signifies much,' she said to herself; ‘I should think it would be quite as much use in the trial one way up as the other.'\\nAs soon as the jury had a little recovered from the shock of being upset, and their slates and pencils had been found and handed back to them, they set to work very diligently to write out a history of the accident, all except the Lizard, who seemed too much overcome to do anything but sit with its mouth open, gazing up into the roof of the court.\\n‘What do you know about this business?' the King said to Alice.\\n‘Nothing,' said Alice.\\n‘Nothing whatever?' persisted the King.\\n‘Nothing whatever,' said Alice.   \n",
       "2806  Artificial intelligence (AI) is intelligence exhibited by machines. In computer science, an ideal \"intelligent\" machine is a flexible rational agent that perceives its environment and takes actions that maximize its chance of success at some goal. Colloquially, the term \"artificial intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\". As machines become increasingly capable, facilities once thought to require intelligence are removed from the definition. For example, optical character recognition is no longer perceived as an exemplar of \"artificial intelligence\" having become a routine technology. Capabilities still classified as AI include advanced Chess and Go systems and self-driving cars.\\nAI research is divided into subfields that focus on specific problems or on specific approaches or on the use of a particular tool or towards satisfying particular applications.   \n",
       "\n",
       "        target  fold  \n",
       "2089 -0.432678     2  \n",
       "2806 -1.161746     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "competition_data = pd.read_csv(\"commonlit-splits/commonlittrain_stratified_simple.csv\")[['excerpt', 'target', 'fold']]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(competition_data.sample(2, random_state=config['seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47551ed-c0e9-4c01-b78c-5268fbd488d9",
   "metadata": {},
   "source": [
    "## Target exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e234bc9-fde1-4010-98d5-5943cc0adcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(competition_data.target.to_numpy())\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94d331-dfd1-4956-a220-9c494612d78d",
   "metadata": {},
   "source": [
    "## Text exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b01bf-2449-46df-8da0-4438afc0c62c",
   "metadata": {},
   "source": [
    "### Very easy text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664d3417-8c89-4d0a-b466-21e3801eeb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>For her last birthday, Sisanda had a special treat – her parents got permission for her to have a party at the game reserve. The giraffes at the reserve were curious about this group of people. They stretched out their long necks for the best view of the party and they even seemed to want some of the birthday cake! Sisanda loved the giraffes. All animals were special to her, but it was the quiet and gentle giraffes that stole her heart. She could spend all day watching them. \\nOne Friday, Sisanda's father came home from work early. He looked very upset. \"What's wrong, Baba?\" Sisanda asked. \"Today a swarm of bees stung a mother giraffe,\" explained Sisanda's father. \"Her head was so swollen from all the stings that her beautiful eyes were closed. We tried everything to help her, but it was no use – she died. And the saddest part of all is that she had a young calf that still needs her.\"</td>\n",
       "      <td>1.59787</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               excerpt  \\\n",
       "981  For her last birthday, Sisanda had a special treat – her parents got permission for her to have a party at the game reserve. The giraffes at the reserve were curious about this group of people. They stretched out their long necks for the best view of the party and they even seemed to want some of the birthday cake! Sisanda loved the giraffes. All animals were special to her, but it was the quiet and gentle giraffes that stole her heart. She could spend all day watching them. \\nOne Friday, Sisanda's father came home from work early. He looked very upset. \"What's wrong, Baba?\" Sisanda asked. \"Today a swarm of bees stung a mother giraffe,\" explained Sisanda's father. \"Her head was so swollen from all the stings that her beautiful eyes were closed. We tried everything to help her, but it was no use – she died. And the saddest part of all is that she had a young calf that still needs her.\"   \n",
       "\n",
       "      target  fold  \n",
       "981  1.59787     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(competition_data.query(\"target>1.5\").sample(1, random_state=config['seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2998a7-2b32-4528-98cb-8f73bba5f8e1",
   "metadata": {},
   "source": [
    "### Very difficult text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3a6071-ab1e-4b6e-9eb0-14f6eefa2c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>The light-year is a unit of length used to express astronomical distances and measures about 9.46 trillion kilometres (9.46 x 1012 km) or 5.88 trillion miles (5.88 x 1012 mi). As defined by the International Astronomical Union (IAU), a light-year is the distance that light travels in vacuum in one Julian year (365.25 days).Because it includes the word \"year\", the term light-year may be misinterpreted as a unit of time.\\nThe light-year is most often used when expressing distances to stars and other distances on a galactic scale, especially in non-specialist and popular science publications. The unit most commonly used in professional astrometry is the parsec (symbol: pc, about 3.26 light-years; the distance at which one astronomical unit subtends an angle of one second of arc).\\n As defined by the IAU, the light-year is the product of the Julian year (365.25 days as opposed to the 365.2425-day Gregorian year) and the speed of light (299792458 m/s). Both of these values are included in the IAU (1976) System of Astronomical Constants, used since 1984.</td>\n",
       "      <td>-3.256312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      excerpt  \\\n",
       "457  The light-year is a unit of length used to express astronomical distances and measures about 9.46 trillion kilometres (9.46 x 1012 km) or 5.88 trillion miles (5.88 x 1012 mi). As defined by the International Astronomical Union (IAU), a light-year is the distance that light travels in vacuum in one Julian year (365.25 days).Because it includes the word \"year\", the term light-year may be misinterpreted as a unit of time.\\nThe light-year is most often used when expressing distances to stars and other distances on a galactic scale, especially in non-specialist and popular science publications. The unit most commonly used in professional astrometry is the parsec (symbol: pc, about 3.26 light-years; the distance at which one astronomical unit subtends an angle of one second of arc).\\n As defined by the IAU, the light-year is the product of the Julian year (365.25 days as opposed to the 365.2425-day Gregorian year) and the speed of light (299792458 m/s). Both of these values are included in the IAU (1976) System of Astronomical Constants, used since 1984.   \n",
       "\n",
       "       target  fold  \n",
       "457 -3.256312     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(competition_data.query(\"target<-3\").sample(1, random_state=config['seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aea5ec-0c75-4401-8870-bb7a80406e15",
   "metadata": {},
   "source": [
    "# External data\n",
    "From Wikipedia and Simple wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaccc619-44a2-4494-b5c4-ca1b6ea93874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>easy_text</th>\n",
       "      <th>difficult_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16115</th>\n",
       "      <td>Epstein–Barr virus</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>It is one of the most common viruses in humans. EBV is best known as the cause of infectious mononucleosis (glandular fever). It is also associated with some forms of cancer, such as Hodgkin's lymphoma, and conditions associated with human immunodeficiency virus (HIV). EBV may be associated with...</td>\n",
       "      <td>EBV is a double-stranded DNA virus. It is best known as the cause of infectious mononucleosis (\"mono\" or \"glandular fever\"). It is also associated with various non-malignant, premalignant, and malignant Epstein–Barr virus-associated lymphoproliferative diseases such as Burkitt lymphoma, hemophag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>Substitute (association football)</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Substitutions can be made for many reasons. Sometimes, they are made to replace a player who has become tired or injured. Substitutes can also replace a player who is playing poorly, or can be for tactics. For example, substitute strikers can be brought on for defenders if the team needs to atta...</td>\n",
       "      <td>Substitutions are generally made to replace a player who has become tired or injured, or who is performing poorly, or for tactical reasons (such as bringing a striker on in place of a defender). Unlike some sports (such as American football, ice hockey or kabaddi), but like in baseball, a player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22575</th>\n",
       "      <td>Ford Pinto</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The vehicle was marketed under Ford Motor Company in the States and Canada. It was made from the 1971 to 1980 model years. Pinto was the smallest American Ford car since 1907. It was Ford's first subcompact vehicle in North America. The Pinto was manufactured in three body styles: two-door sedan...</td>\n",
       "      <td>The smallest American Ford vehicle since 1907, the Pinto was the first subcompact vehicle produced by Ford in North America. The Pinto was marketed in three body styles through its production: a two-door fastback sedan with a trunk, a three-door hatchback, and a two-door station wagon. Mercury o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title   section  \\\n",
       "16115                 Epstein–Barr virus  Abstract   \n",
       "15807  Substitute (association football)  Abstract   \n",
       "22575                         Ford Pinto  Abstract   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         easy_text  \\\n",
       "16115  It is one of the most common viruses in humans. EBV is best known as the cause of infectious mononucleosis (glandular fever). It is also associated with some forms of cancer, such as Hodgkin's lymphoma, and conditions associated with human immunodeficiency virus (HIV). EBV may be associated with...   \n",
       "15807  Substitutions can be made for many reasons. Sometimes, they are made to replace a player who has become tired or injured. Substitutes can also replace a player who is playing poorly, or can be for tactics. For example, substitute strikers can be brought on for defenders if the team needs to atta...   \n",
       "22575  The vehicle was marketed under Ford Motor Company in the States and Canada. It was made from the 1971 to 1980 model years. Pinto was the smallest American Ford car since 1907. It was Ford's first subcompact vehicle in North America. The Pinto was manufactured in three body styles: two-door sedan...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    difficult_text  \n",
       "16115  EBV is a double-stranded DNA virus. It is best known as the cause of infectious mononucleosis (\"mono\" or \"glandular fever\"). It is also associated with various non-malignant, premalignant, and malignant Epstein–Barr virus-associated lymphoproliferative diseases such as Burkitt lymphoma, hemophag...  \n",
       "15807  Substitutions are generally made to replace a player who has become tired or injured, or who is performing poorly, or for tactical reasons (such as bringing a striker on in place of a defender). Unlike some sports (such as American football, ice hockey or kabaddi), but like in baseball, a player...  \n",
       "22575  The smallest American Ford vehicle since 1907, the Pinto was the first subcompact vehicle produced by Ford in North America. The Pinto was marketed in three body styles through its production: a two-door fastback sedan with a trunk, a three-door hatchback, and a two-door station wagon. Mercury o...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "external_data = pd.read_csv(\"data/external_data/wikipedia_sections_without_first_sentence.csv\")\n",
    "external_data = external_data[['title', 'section', 'easy_text', 'difficult_text']]\n",
    "\n",
    "with pd.option_context(\"display.max_colwidth\", 300):\n",
    "    display(external_data.sample(3, random_state=config['seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad156a-2236-4687-8183-4469b6c65bf1",
   "metadata": {},
   "source": [
    "# Competition DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eced35ee-6f7b-446e-a356-6f551c1dc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({'fold': 0, 'batch_size': 4, 'apply_preprocessing': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b375a8f-c546-43c0-be90-0653bef9ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train_data: 2267\n",
      "Number of sample in the valid_data: 567\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = competition_data[competition_data['fold'] != config['fold']], competition_data[competition_data['fold']==config['fold']]\n",
    "print(f'Number of samples in the train_data: {len(train_data)}')\n",
    "print(f'Number of sample in the valid_data: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328a27b-f376-4e2c-b563-f13f43225058",
   "metadata": {},
   "source": [
    "### Dataset Definition\n",
    "```python\n",
    "class UnoTextDataset(Dataset):\n",
    "    def __init__(self, text_excerpts, targets):\n",
    "        self.text_excerpts = text_excerpts\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_excerpts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'text_excerpt': self.text_excerpts[idx],\n",
    "                  'target': self.targets[idx]}\n",
    "        return sample\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c015a2b-d6ee-4895-b517-80a7f5073458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the train_dataloader: 567\n",
      "Number of batches in the valid_dataloader: 142\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = create_uno_text_dataloader(data=train_data, batch_size=config['batch_size'], shuffle=True, sampler=None, apply_preprocessing=config['apply_preprocessing'])\n",
    "valid_dataloader = create_uno_text_dataloader(data=valid_data, batch_size=config['batch_size'], shuffle=False, sampler=None, apply_preprocessing=config['apply_preprocessing'])\n",
    "print(f'Number of batches in the train_dataloader: {len(train_dataloader)}')\n",
    "print(f'Number of batches in the valid_dataloader: {len(valid_dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c5095-c35b-4706-b4a2-e035a31882cc",
   "metadata": {},
   "source": [
    "# Define Tokenizer and Model\n",
    "1. Discuss dropout\n",
    "2. Discuss Model designs\n",
    "\n",
    "---\n",
    "```python\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, input_dim, head_hidden_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        head_hidden_dim = input_dim if head_hidden_dim is None else head_hidden_dim\n",
    "        self.W = nn.Linear(input_dim, head_hidden_dim)\n",
    "        self.V = nn.Linear(head_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_scores = self.V(torch.tanh(self.W(x)))\n",
    "        attention_scores = torch.softmax(attention_scores, dim=1)\n",
    "        attentive_x = attention_scores * x\n",
    "        attentive_x = attentive_x.sum(axis=1)\n",
    "        return attentive_x\n",
    "```\n",
    "---\n",
    "\n",
    "```python\n",
    "class MaskAddedAttentionHead(nn.Module):\n",
    "    def __init__(self, input_dim, head_hidden_dim):\n",
    "        super(MaskAddedAttentionHead, self).__init__()\n",
    "        head_hidden_dim = input_dim if head_hidden_dim is None else head_hidden_dim\n",
    "        self.W = nn.Linear(input_dim, head_hidden_dim)\n",
    "        self.V = nn.Linear(head_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, attention_mask):\n",
    "        attention_scores = self.V(torch.tanh(self.W(x)))\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "        attention_scores = torch.softmax(attention_scores, dim=1)\n",
    "        attentive_x = attention_scores * x\n",
    "        attentive_x = attentive_x.sum(axis=1)\n",
    "        return attentive_x\n",
    "```\n",
    "---\n",
    "\n",
    "```python\n",
    "class RobertaMaskAddedAttentionHeadRegressor(nn.Module):\n",
    "    def __init__(self, model_path, dropout_prob=0.1, head_hidden_dim=None, roberta_hidden_dropout_prob=0.1,\n",
    "                 roberta_attention_probs_dropout_prob=0.1, **kwargs):\n",
    "        super(RobertaMaskAddedAttentionHeadRegressor, self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(model_path,\n",
    "                                                 hidden_dropout_prob=roberta_hidden_dropout_prob,\n",
    "                                                 attention_probs_dropout_prob=roberta_attention_probs_dropout_prob, **kwargs)\n",
    "        self.head = MaskAddedAttentionHead(input_dim=self.roberta.config.hidden_size, head_hidden_dim=head_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.regressor = nn.Linear(self.roberta.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        roberta_outputs = self.roberta(**inputs)\n",
    "        last_hidden_state = roberta_outputs['last_hidden_state']\n",
    "        attentive_vector = self.head(last_hidden_state, torch.unsqueeze(inputs['attention_mask'], dim=2))\n",
    "        attentive_vector = self.dropout(attentive_vector)\n",
    "        logits = self.regressor(attentive_vector)\n",
    "        return logits\n",
    "```\n",
    "---\n",
    "\n",
    "```python\n",
    "    class RobertaLastHiddenStateMeanPooler(nn.Module):\n",
    "        def __init__(self, model_path, dropout_prob=0.1, head_hidden_dim=None,  roberta_hidden_dropout_prob=0.1, roberta_attention_probs_dropout_prob=0.1, **kwargs):\n",
    "            super(RobertaLastHiddenStateMeanPooler, self).__init__()\n",
    "            self.roberta = AutoModel.from_pretrained(model_path,\n",
    "                                                     hidden_dropout_prob=roberta_hidden_dropout_prob,\n",
    "                                                     attention_probs_dropout_prob=roberta_attention_probs_dropout_prob, **kwargs)\n",
    "            self.dropout = nn.Dropout(dropout_prob)\n",
    "            self.regressor = nn.Linear(self.roberta.config.hidden_size, 1)\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            roberta_outputs = self.roberta(**inputs)\n",
    "            last_hidden_state = roberta_outputs['last_hidden_state']\n",
    "            masked_last_hidden_state = last_hidden_state * torch.unsqueeze(inputs['attention_mask'], dim=2)\n",
    "            num_tokens = torch.unsqueeze(inputs['attention_mask'], dim=2)\n",
    "            num_tokens = torch.clamp(num_tokens, min=1e-9)\n",
    "            mean_embeddings = masked_last_hidden_state.sum(axis=1) / num_tokens.sum(axis=1)\n",
    "            mean_embeddings = self.dropout(mean_embeddings)\n",
    "            logits = self.regressor(mean_embeddings)\n",
    "            return logits\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89de525b-90ec-488f-aa4d-f18d152e910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = RobertaMaskAddedAttentionHeadRegressor\n",
    "config = {'base_model_path': 'data/robertas/roberta-base',\n",
    "          'tokenizer_name': 'data/robertas/roberta-base',\n",
    "          'head_hidden_dim': 512,\n",
    "          'dropout_prob': 0.0,\n",
    "          'roberta_hidden_dropout_prob': 0.0,\n",
    "          'roberta_attention_probs_dropout_prob': 0.0,\n",
    "          'layer_norm_eps': 1e-7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d83a4b-6fda-4740-9828-5038451a1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cuda()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=config['tokenizer_name'])\n",
    "model = model_class(model_path=config['base_model_path'],\n",
    "                    head_hidden_dim=config['head_hidden_dim'],\n",
    "                    dropout_prob=config['dropout_prob'],\n",
    "                    roberta_hidden_dropout_prob=config['roberta_hidden_dropout_prob'],\n",
    "                    roberta_attention_probs_dropout_prob=config['roberta_attention_probs_dropout_prob'],\n",
    "                    layer_norm_eps=config['layer_norm_eps'])\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f6879-46b9-4d41-8d66-2cf2f831e4c3",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "```python\n",
    "    def get_optimizer_parameters(group_mode, lr, model, **kwargs):\n",
    "        # group_mode == 'be_wd':\n",
    "        multiplicative_factor = kwargs['multiplicative_factor']\n",
    "        weight_decay = kwargs['weight_decay']\n",
    "        max_num_layers = model.roberta.config.num_hidden_layers\n",
    "\n",
    "        # Task Specific Layer group\n",
    "        tsl_param_group = [{'params': [param for name, param in model.named_parameters() if 'roberta' not in name],\n",
    "                            'param_names': [name for name, param in model.named_parameters() if 'roberta' not in name],\n",
    "                            'lr': lr,\n",
    "                            'name': 'tsl'}]\n",
    "\n",
    "        # Roberta Layer group\n",
    "        roberta_layers_param_groups = []\n",
    "        for layer_num in reversed(range(max_num_layers)):\n",
    "            roberta_layer_param_groups = {'params': [param for name, param in model.named_parameters()\n",
    "                                                     if f'roberta.encoder.layer.{layer_num}.' in name],\n",
    "                                          'param_names': [name for name, param in model.named_parameters()\n",
    "                                                          if f'roberta.encoder.layer.{layer_num}.' in name],\n",
    "                                          'lr': lr * (multiplicative_factor ** (max_num_layers - layer_num)),\n",
    "                                          'name': f'layer_{layer_num}'}\n",
    "            roberta_layers_param_groups.append(roberta_layer_param_groups)\n",
    "\n",
    "        # Embeddding group\n",
    "        embedding_lr = lr * (multiplicative_factor ** (max_num_layers + 1))\n",
    "        embedding_param_group = [{'params': [param for name, param in model.named_parameters() if 'embedding' in name],\n",
    "                                  'param_names': [name for name, param in model.named_parameters() if 'embedding' in name],\n",
    "                                  'lr': embedding_lr,\n",
    "                                  'name': 'embedding'}]\n",
    "\n",
    "        param_groups = tsl_param_group + roberta_layers_param_groups + embedding_param_group\n",
    "        optimizer_parameters = list(chain(*[split_into_wd_groups(param_group, weight_decay=weight_decay)\n",
    "                                            for param_group in param_groups]))\n",
    "        return optimizer_parameters\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "    def split_into_wd_groups(param_group, weight_decay):\n",
    "        # Applies weight decay\n",
    "        weight_parameters = {'params': [param_group['params'][index]\n",
    "                                        for index, name in enumerate(param_group['param_names'])\n",
    "                                        if 'weight' in name and 'LayerNorm' not in name],\n",
    "                             'param_names': [param_group['param_names'][index] \n",
    "                                             for index, name in enumerate(param_group['param_names'])\n",
    "                                             if 'weight' in name and 'LayerNorm' not in name],\n",
    "                             'lr': param_group['lr'],\n",
    "                             'weight_decay': weight_decay,\n",
    "                             'name': param_group['name']+'_weight'}\n",
    "        # Does not apply weight decay\n",
    "        bias_ln_parameters = {'params': [param_group['params'][index]\n",
    "                                         for index, name in enumerate(param_group['param_names'])\n",
    "                                         if 'bias' in name or 'LayerNorm' in name],\n",
    "                              'param_names': [param_group['param_names'][index]\n",
    "                                              for index, name in enumerate(param_group['param_names'])\n",
    "                                              if 'bias' in name or 'LayerNorm' in name],\n",
    "                              'lr': param_group['lr'],\n",
    "                              'weight_decay': 0.0,\n",
    "                              'name': param_group['name']+'_bias_ln'}\n",
    "        parameters = [weight_parameters, bias_ln_parameters]\n",
    "        return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e06c5539-1572-4240-af5b-24e245117021",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({'group_mode': 'be_wd',\n",
    "               'lr': 3e-5,\n",
    "               'multiplicative_factor': 0.95,\n",
    "               'weight_decay': 0.01,\n",
    "               'eps': 1e-7,\n",
    "               'scheduler_type': 'cosine_schedule_with_warmup',\n",
    "               'num_warmup_steps': 0,\n",
    "               'num_epochs': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737d7607-5e5d-4c51-aba2-db2ff90bda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = get_optimizer_parameters(group_mode=config['group_mode'], lr=config['lr'],\n",
    "                                                model=model, multiplicative_factor=config['multiplicative_factor'], \n",
    "                                                weight_decay=config['weight_decay'])\n",
    "optimizer = AdamW(optimizer_parameters, eps=config['eps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf73ef5c-f5da-4665-910f-1a62f8b6106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_scheduler(scheduler_type=config['scheduler_type'], optimizer=optimizer,\n",
    "                          num_warmup_steps=config['num_warmup_steps'],\n",
    "                          num_training_steps=config['num_epochs'] * len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dc060ff-9e7b-4c1a-afe9-270a6525ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({'should_save_best_valid_loss_model': False,\n",
    "               'should_save_best_valid_score_model': False,\n",
    "               'should_save_final_model': False,\n",
    "               'save_name': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4429a60-b8f3-42b2-b90c-b63e7590a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss_saver = Saver(metric_name='rmse_loss', is_lower_better=True, config=config, save_name=config['save_name'], should_save=config['should_save_best_valid_loss_model'])\n",
    "valid_score_saver = Saver(metric_name='rmse_score', is_lower_better=True, config=config, save_name=config['save_name'], should_save=config['should_save_best_valid_score_model'])\n",
    "final_model_saver = Saver(metric_name='final_model', is_lower_better=True, config=config, save_name=config['save_name'], should_save=config['should_save_final_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847fbe2f-d6b4-41f3-8cd5-1b58ff0d3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update({'max_length': 256,\n",
    "               'accumulation_steps': 1,\n",
    "               'validate_every_n_iteration': 1,\n",
    "               'validate_after_n_iteration': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25aac3b-5e30-45dd-88b9-62285beb6e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_num: 0, iteration_num: 0, iteration_train_loss: 1.5604248046875\n",
      "Epoch_num: 0, iteration_num: 1, iteration_train_loss: 0.5501980185508728\n",
      "rmse_loss attained best score: 1.083. Saving the model\n",
      "rmse_score attained best score: 1.182. Saving the model\n",
      "Epoch_num: 0, iteration_num: 1, iteration_train_loss: 0.5501980185508728\n",
      "Epoch_num: 0, iteration_num: 1, valid_loss: 1.082701914956872, valid_score: 1.1816993951797485\n",
      "Epoch_num: 0, iteration_num: 2, iteration_train_loss: 0.7932721376419067\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13970/2643684352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        \u001b[0mvalidate_after_n_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validate_after_n_iteration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        \u001b[0mvalid_loss_saver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loss_saver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_score_saver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_score_saver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_model_saver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model_saver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                        device=device)\n\u001b[0m",
      "\u001b[0;32m~/kaggle_commonlit/commonlit_nn_kit.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(num_epochs, train_dataloader, valid_dataloader, tokenizer, model, optimizer, scheduler, forward_pass_fn_train, forward_pass_fn_valid, compute_loss_fn_train, compute_loss_fn_valid, compute_metric_fn, stacker_class, max_length, accumulation_steps, validate_every_n_iteraion, valid_loss_saver, valid_score_saver, device, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                                                    \u001b[0mforward_pass_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward_pass_fn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss_fn_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                                                    \u001b[0mcompute_metric_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metric_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacker_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacker_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                                                    max_length=max_length, device=device, **kwargs)\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0mvalid_loss_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_iteration_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mvalid_score_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_iteration_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_commonlit/commonlit_nn_kit.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataloader, tokenizer, model, forward_pass_fn, compute_loss_fn, compute_metric_fn, stacker_class, max_length, device, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             batch_outputs = forward_pass_fn(batch=batch, tokenizer=tokenizer, model=model, \n\u001b[1;32m    589\u001b[0m                                             \u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                                             device=device, **kwargs)\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_commonlit/commonlit_nn_kit.py\u001b[0m in \u001b[0;36mforward_pass_uno_text_batch\u001b[0;34m(batch, tokenizer, model, compute_loss_fn, max_length, device, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass_uno_text_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_excerpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_excerpt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompute_loss_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_commonlit/commonlit_nn_kit.py\u001b[0m in \u001b[0;36mcompute_predictions\u001b[0;34m(text_excerpts, tokenizer, model, max_length, device, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_excerpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_commonlit/commonlit_nn_kit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mroberta_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mattentive_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                 )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/kaggle_commonlit/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = train_and_evaluate(num_epochs=config['num_epochs'], train_dataloader=train_dataloader, valid_dataloader=valid_dataloader,\n",
    "                       tokenizer=tokenizer, model=model, optimizer=optimizer, scheduler=scheduler,\n",
    "                       forward_pass_fn_train=forward_pass_uno_text_batch, forward_pass_fn_valid=forward_pass_uno_text_batch,\n",
    "                       compute_loss_fn_train=compute_mse_loss, compute_loss_fn_valid=compute_rmse_loss,\n",
    "                       compute_metric_fn=compute_rmse_score, stacker_class=UnoStacker, max_length=config['max_length'],\n",
    "                       accumulation_steps=config['accumulation_steps'], validate_every_n_iteraion=config['validate_every_n_iteration'],\n",
    "                       validate_after_n_iteration=config['validate_after_n_iteration'],\n",
    "                       valid_loss_saver=valid_loss_saver, valid_score_saver=valid_score_saver, final_model_saver=final_model_saver,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c9246-86de-49bb-9842-ec2cbb79b526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_commonlit",
   "language": "python",
   "name": "kaggle_commonlit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
